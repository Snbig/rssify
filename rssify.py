import os
from urllib.parse import urljoin
from datetime import datetime
import requests
from feedgen.feed import FeedGenerator
from bs4 import BeautifulSoup
from pytz import timezone

title = os.environ.get('TITLE')
subtitle = os.environ.get('SUBTITLE')
url = os.environ.get('URL')
item_title_selector = os.environ.get('ITEM_TITLE_CSS')
item_url_selector = os.environ.get('ITEM_URL_CSS')
item_description_selector = os.environ.get('ITEM_DESCRIPTION_CSS')
item_date_selector = os.environ.get('ITEM_DATE_CSS')
item_date_format = os.environ.get('ITEM_DATE_FORMAT')
item_timezone = os.environ.get('ITEM_TIMEZONE')

r = requests.get(url)
soup = BeautifulSoup(r.text, 'lxml')
titles = soup.select(item_title_selector)
urls = soup.select(item_url_selector)

descriptions = []
if item_description_selector:
    descriptions = soup.select(item_description_selector)

dates = []
if item_date_selector:
    dates = soup.select(item_date_selector)

fg = FeedGenerator()
fg.title(title)
if subtitle:
    fg.subtitle(subtitle)
else:
    fg.subtitle('Generated by TabHub Rssify(https://tabhub.github.io/)')
fg.link(href='https://tabhub.github.io/', rel='alternate')

for i in range(len(titles)):
    if i > len(urls) - 1:
        break

    fe = fg.add_entry()
    fe.title(titles[i].text)
    fe.link(href=urljoin(url, urls[i].get('href')), rel='alternate')
    if descriptions and descriptions[i]:
        fe.description(descriptions[i].text)
    if dates and item_date_format:
        date = datetime.strptime(dates[i].text.strip(), item_date_format)
        if item_timezone:
            localtz = timezone(item_timezone)
            date = localtz.localize(date)
    else:
        #date = datetime.now(timezone("Europe/Berlin"))
        date = '1970-01-01 00:00:00+02:00'

    fe.published(date)

fg.rss_file('rss.xml')
